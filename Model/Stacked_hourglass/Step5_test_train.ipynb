{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tropical-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "from os.path import dirname\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "cudnn.enabled = True\n",
    "\n",
    "import torch\n",
    "import importlib\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "import shutil\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-television",
   "metadata": {},
   "source": [
    "# terminal => code  \n",
    "Ex) python train.py -c test_run_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sufficient-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_command_line():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-c', '--continue_exp', type=str, help='continue exp')\n",
    "    parser.add_argument('-e', '--exp', type=str, default='pose', help='experiments name')\n",
    "    parser.add_argument('-m', '--max_iters', type=int, default=250, help='max number of iterations (thousands)')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "satellite-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reload(config):\n",
    "    \"\"\"\n",
    "    load or initialize model's parameters by config from config['opt'].continue_exp\n",
    "    config['train']['epoch'] records the epoch num\n",
    "    config['inference']['net'] is the model\n",
    "    \"\"\"\n",
    "    opt = config['opt']\n",
    "\n",
    "    if opt.continue_exp:\n",
    "        ########## File Reload ####################\n",
    "        \n",
    "        resume = os.path.join('exp', opt.continue_exp)\n",
    "        resume_file = os.path.join(resume, 'checkpoint.pt')\n",
    "        \n",
    "        \n",
    "        \n",
    "        if os.path.isfile(resume_file):\n",
    "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "            checkpoint = torch.load(resume_file)\n",
    "\n",
    "            config['inference']['net'].load_state_dict(checkpoint['state_dict'])\n",
    "            config['train']['optimizer'].load_state_dict(checkpoint['optimizer'])\n",
    "            config['train']['epoch'] = checkpoint['epoch']\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(resume, checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "            exit(0)\n",
    "\n",
    "    if 'epoch' not in config['train']:\n",
    "        config['train']['epoch'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unexpected-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckp_path='/home/lab/양창희/Pose Estimation/stacked_hourglass/pytorch_stacked_hourglass-master/exp/test_run_001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "digital-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_file = os.path.join(ckp_path,'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "regular-latter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lab/양창희/Pose Estimation/stacked_hourglass/pytorch_stacked_hourglass-master/exp/test_run_001/checkpoint.pt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "disturbed-fabric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(resume_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "structured-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(resume_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "norman-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint['state_dict'] => model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "occupational-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint['optimizer'] => model optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "greater-gauge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smaller-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pt'):\n",
    "    \n",
    "    ################# state ###############################\n",
    "    #        'state_dict': config['inference']['net'].state_dict(),\n",
    "    #        'optimizer' : config['train']['optimizer'].state_dict(),\n",
    "    #        'epoch': config['train']['epoch'],\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    from pytorch/examples\n",
    "    \"\"\"\n",
    "    basename = dirname(filename)\n",
    "    if not os.path.exists(basename):\n",
    "        os.makedirs(basename)\n",
    "    torch.save(state, filename) #=> Save net, optimizer, epoch\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "furnished-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(config):\n",
    "    resume = os.path.join('exp', config['opt'].exp)\n",
    "    if config['opt'].exp=='pose' and config['opt'].continue_exp is not None:\n",
    "        resume = os.path.join('exp', config['opt'].continue_exp)\n",
    "    resume_file = os.path.join(resume, 'checkpoint.pt')\n",
    "\n",
    "    save_checkpoint({\n",
    "            'state_dict': config['inference']['net'].state_dict(),\n",
    "            'optimizer' : config['train']['optimizer'].state_dict(),\n",
    "            'epoch': config['train']['epoch'],\n",
    "        }, False, filename=resume_file)\n",
    "    print('=> save checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_func, data_func, config, post_epoch=None):\n",
    "    \n",
    "    # data_ func => config['data+provider']\n",
    "    while True:\n",
    "        fails = 0\n",
    "        print('epoch: ', config['train']['epoch'])\n",
    "        if 'epoch_num' in config['train']:\n",
    "            if config['train']['epoch'] > config['train']['epoch_num']:\n",
    "                break\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            num_step = config['train']['{}_iters'.format(phase)]\n",
    "            generator = data_func(phase)\n",
    "            print('start', phase, config['opt'].exp)\n",
    "\n",
    "            show_range = range(num_step)\n",
    "            show_range = tqdm.tqdm(show_range, total = num_step, ascii=True)\n",
    "            batch_id = num_step * config['train']['epoch']\n",
    "            if batch_id > config['opt'].max_iters * 1000:\n",
    "                return\n",
    "            for i in show_range:\n",
    "                datas = next(generator)\n",
    "                outs = train_func(batch_id + i, config, phase, **datas)\n",
    "        config['train']['epoch'] += 1\n",
    "        save(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "latin-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    \"\"\"\n",
    "    task.__config__ contains the variables that control the training and testing\n",
    "    make_network builds a function which can do forward and backward propagation\n",
    "    \"\"\"\n",
    "    opt = parse_command_line()\n",
    "    task = importlib.import_module('task.pose')\n",
    "    #=> pose\n",
    "    exp_path = os.path.join('exp', opt.exp)\n",
    "    \n",
    "    current_time = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "    config = task.__config__\n",
    "    try: os.makedirs(exp_path)\n",
    "    except FileExistsError: pass\n",
    "\n",
    "    config['opt'] = opt\n",
    "    config['data_provider'] = importlib.import_module(config['data_provider'])\n",
    "    #=> dp\n",
    "\n",
    "    func = task.make_network(config)\n",
    "    reload(config)\n",
    "    return func, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ready-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    func, config =init()\n",
    "    data_func = config['data_provider'].init(config)\n",
    "    train(func, data_func, config)\n",
    "    print(datetime.now(timezone('EST')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
