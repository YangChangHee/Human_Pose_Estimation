{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "terminal-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import copy\n",
    "\n",
    "from group import HeatmapParser\n",
    "import img as iimg\n",
    "import ref as ds\n",
    "import easydict\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-regression",
   "metadata": {},
   "source": [
    "## parser => util.group => make pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = HeatmapParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legal-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(det, mat_, trainval, c=None, s=None, resolution=None):\n",
    "    mat = np.linalg.pinv(np.array(mat_).tolist() + [[0,0,1]])[:2]\n",
    "    res = det.shape[1:3]\n",
    "    cropped_preds = parser.parse(np.float32([det]))[0]\n",
    "    \n",
    "    if len(cropped_preds) > 0:\n",
    "        cropped_preds[:,:,:2] = utilss.img.kpt_affine(cropped_preds[:,:,:2] * 4, mat) #size 1x16x3\n",
    "        \n",
    "    preds = np.copy(cropped_preds)\n",
    "    ##for inverting predictions from input res on cropped to original image\n",
    "    if trainval != 'cropped':\n",
    "        for j in range(preds.shape[1]):\n",
    "            preds[0,j,:2] = utilss.img.transform(preds[0,j,:2], c, s, resolution, invert=1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "allied-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(img, func, config, c, s):\n",
    "    \"\"\"\n",
    "    forward pass at test time\n",
    "    calls post_process to post process results\n",
    "    \"\"\"\n",
    "    \n",
    "    height, width = img.shape[0:2]\n",
    "    center = (width/2, height/2)\n",
    "    scale = max(height, width)/200\n",
    "    res = (config['train']['input_res'], config['train']['input_res'])\n",
    "\n",
    "    mat_ = utilss.img.get_transform(center, scale, res)[:2]\n",
    "    inp = img/255\n",
    "\n",
    "    def array2dict(tmp):\n",
    "        return {\n",
    "            'det': tmp[0][:,:,:16],\n",
    "        }\n",
    "\n",
    "    tmp1 = array2dict(func([inp]))\n",
    "    tmp2 = array2dict(func([inp[:,::-1]]))\n",
    "\n",
    "    tmp = {}\n",
    "    for ii in tmp1:\n",
    "        tmp[ii] = np.concatenate((tmp1[ii], tmp2[ii]),axis=0)\n",
    "\n",
    "    det = tmp['det'][0, -1] + tmp['det'][1, -1, :, :, ::-1][ds.flipped_parts['mpii']]\n",
    "    if det is None:\n",
    "        return [], []\n",
    "    det = det/2\n",
    "\n",
    "    det = np.minimum(det, 1)\n",
    "    \n",
    "    return post_process(det, mat_, 'valid', c, s, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-piece",
   "metadata": {},
   "source": [
    "tmp1, tmp2 => model_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inner-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpii_eval(pred, gt, normalizing, num_train, bound=0.5):\n",
    "    \"\"\"\n",
    "    Use PCK with threshold of .5 of normalized distance (presumably head size)\n",
    "    \"\"\"\n",
    "\n",
    "    correct = {'all': {'total': 0, 'ankle': 0, 'knee': 0, 'hip': 0, 'pelvis': 0, \n",
    "               'thorax': 0, 'neck': 0, 'head': 0, 'wrist': 0, 'elbow': 0, \n",
    "               'shoulder': 0},\n",
    "               'visible': {'total': 0, 'ankle': 0, 'knee': 0, 'hip': 0, 'pelvis': 0, \n",
    "               'thorax': 0, 'neck': 0, 'head': 0, 'wrist': 0, 'elbow': 0, \n",
    "               'shoulder': 0},\n",
    "               'not visible': {'total': 0, 'ankle': 0, 'knee': 0, 'hip': 0, 'pelvis': 0, \n",
    "               'thorax': 0, 'neck': 0, 'head': 0, 'wrist': 0, 'elbow': 0, \n",
    "               'shoulder': 0}}\n",
    "    count = copy.deepcopy(correct)\n",
    "    correct_train = copy.deepcopy(correct)\n",
    "    count_train = copy.deepcopy(correct)\n",
    "    idx = 0\n",
    "    for p, g, normalize in zip(pred, gt, normalizing):\n",
    "        for j in range(g.shape[1]):\n",
    "            vis = 'visible'\n",
    "            if g[0,j,0] == 0: ## not in picture!\n",
    "                continue\n",
    "            if g[0,j,2] == 0:\n",
    "                vis = 'not visible'\n",
    "            joint = 'ankle'\n",
    "            if j==1 or j==4:\n",
    "                joint = 'knee'\n",
    "            elif j==2 or j==3:\n",
    "                joint = 'hip'\n",
    "            elif j==6:\n",
    "                joint = 'pelvis'\n",
    "            elif j==7:\n",
    "                joint = 'thorax'\n",
    "            elif j==8:\n",
    "                joint = 'neck'\n",
    "            elif j==9:\n",
    "                joint = 'head'\n",
    "            elif j==10 or j==15:\n",
    "                joint = 'wrist'\n",
    "            elif j==11 or j==14:\n",
    "                joint = 'elbow'\n",
    "            elif j==12 or j==13:\n",
    "                joint = 'shoulder'\n",
    "\n",
    "            if idx >= num_train:\n",
    "                count['all']['total'] += 1\n",
    "                count['all'][joint] += 1\n",
    "                count[vis]['total'] += 1\n",
    "                count[vis][joint] += 1\n",
    "            else:\n",
    "                count_train['all']['total'] += 1\n",
    "                count_train['all'][joint] += 1    \n",
    "                count_train[vis]['total'] += 1\n",
    "                count_train[vis][joint] += 1    \n",
    "            error = np.linalg.norm(p[0]['keypoints'][j,:2]-g[0,j,:2]) / normalize\n",
    "            # matrix or vector norm\n",
    "            if idx >= num_train:\n",
    "                if bound > error:\n",
    "                    correct['all']['total'] += 1\n",
    "                    correct['all'][joint] += 1\n",
    "                    correct[vis]['total'] += 1\n",
    "                    correct[vis][joint] += 1\n",
    "            else:\n",
    "                if bound > error:\n",
    "                    correct_train['all']['total'] += 1\n",
    "                    correct_train['all'][joint] += 1\n",
    "                    correct_train[vis]['total'] += 1\n",
    "                    correct_train[vis][joint] += 1  \n",
    "        idx += 1\n",
    "    \n",
    "    ## breakdown by validation set / training set\n",
    "    for k in correct:\n",
    "        print(k, ':')\n",
    "        for key in correct[k]:\n",
    "            print('Val PCK @,', bound, ',', key, ':', round(correct[k][key] / max(count[k][key],1), 3), ', count:', count[k][key])\n",
    "            print('Tra PCK @,', bound, ',', key, ':', round(correct_train[k][key] / max(count_train[k][key],1), 3), ', count:', count_train[k][key])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-admission",
   "metadata": {},
   "source": [
    "Normalized => head size   \n",
    "error = np.linalg.norm(p[0]['keypoints'][j,:2]-g[0,j,:2]) / normalize => Author error code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "frozen-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(config, num_eval=2958, num_train=300):\n",
    "    '''\n",
    "    Load validation and training images\n",
    "    '''\n",
    "    input_res = config['train']['input_res']\n",
    "    output_res = config['train']['output_res']\n",
    "    val_f = h5py.File(os.path.join(ds.annot_dir, 'valid.h5'), 'r')\n",
    "    \n",
    "    tr = tqdm.tqdm( range(0, num_train), total = num_train )\n",
    "    ## training\n",
    "    train_f = h5py.File(os.path.join(ds.annot_dir, 'train.h5') ,'r')\n",
    "    for i in tr:\n",
    "        path_t = '%s/%s' % (ds.img_dir, train_f['imgname'][i].decode('UTF-8'))        \n",
    "        \n",
    "        ## img\n",
    "        orig_img = cv2.imread(path_t)[:,:,::-1]\n",
    "        c = train_f['center'][i]\n",
    "        s = train_f['scale'][i]\n",
    "        im = utilss.img.crop(orig_img, c, s, (input_res, input_res))\n",
    "        \n",
    "        ## kp\n",
    "        kp = train_f['part'][i]\n",
    "        vis = train_f['visible'][i]\n",
    "        kp2 = np.insert(kp, 2, vis, axis=1)\n",
    "        kps = np.zeros((1, 16, 3))\n",
    "        kps[0] = kp2\n",
    "        \n",
    "        ## normalize (to make errors more fair on high pixel imgs)\n",
    "        n = train_f['normalize'][i]\n",
    "        \n",
    "        yield kps, im, c, s, n\n",
    "    tr2 = tqdm.tqdm( range(0, num_eval), total = num_eval )\n",
    "    ## validation\n",
    "    for i in tr2:\n",
    "        path_t = '%s/%s' % (ds.img_dir, val_f['imgname'][i].decode('UTF-8')) \n",
    "        \n",
    "        ## img\n",
    "        orig_img = cv2.imread(path_t)[:,:,::-1]\n",
    "        c = val_f['center'][i]\n",
    "        s = val_f['scale'][i]\n",
    "        im = utilss.img.crop(orig_img, c, s, (input_res, input_res))\n",
    "        \n",
    "        ## kp\n",
    "        kp = val_f['part'][i]\n",
    "        vis = val_f['visible'][i]\n",
    "        kp2 = np.insert(kp, 2, vis, axis=1)\n",
    "        kps = np.zeros((1, 16, 3))\n",
    "        kps[0] = kp2\n",
    "        \n",
    "        ## normalize (to make errors more fair on high pixel imgs)\n",
    "        n = val_f['normalize'][i]\n",
    "        \n",
    "        yield kps, im, c, s, n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-dollar",
   "metadata": {},
   "source": [
    "train image => 300, val image 2958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    from train import init\n",
    "    ###################### Reload Checkpoint #######################\n",
    "    func, config = init()\n",
    "\n",
    "    \n",
    "    def runner(imgs):\n",
    "        return func(0, config, 'inference', imgs=torch.Tensor(np.float32(imgs)))['preds']\n",
    "\n",
    "    def do(img, c, s):\n",
    "        ans = inference(img, runner, config, c, s)\n",
    "        if len(ans) > 0:\n",
    "            ans = ans[:,:,:3]\n",
    "\n",
    "        ## ans has shape N,16,3 (num preds, joints, x/y/visible)\n",
    "        pred = []\n",
    "        for i in range(ans.shape[0]):\n",
    "            pred.append({'keypoints': ans[i,:,:]})\n",
    "        return pred\n",
    "\n",
    "    gts = []\n",
    "    preds = []\n",
    "    normalizing = []\n",
    "    \n",
    "    num_eval = config['inference']['num_eval']\n",
    "    num_train = config['inference']['train_num_eval']\n",
    "    for anns, img, c, s, n in get_img(config, num_eval, num_train):\n",
    "        gts.append(anns)\n",
    "        pred = do(img, c, s)\n",
    "        preds.append(pred)\n",
    "        normalizing.append(n)\n",
    "\n",
    "    mpii_eval(preds, gts, normalizing, num_train)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-adams",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-hazard",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-disabled",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-satellite",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
